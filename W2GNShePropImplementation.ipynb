{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1WkYLiJdUAWDyESrs-iKqE64PdqBhiZdD",
      "authorship_tag": "ABX9TyNAyAXzolkX3Oe8/xHwpyyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaMalik123/Generative-Networks/blob/main/W2GNShePropImplementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First upload local copy of Python scripts into the Google Colab temporary file storage. Then unzip content for use"
      ],
      "metadata": {
        "id": "jST0FzVmRrjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ZaMalik123/Generative-Networks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYPe4mHjyyCF",
        "outputId": "fc7a4e4e-6780-4e6c-91a8-d1878c1541aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Generative-Networks'...\n",
            "remote: Enumerating objects: 104, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 104 (delta 0), reused 3 (delta 0), pack-reused 90\u001b[K\n",
            "Receiving objects: 100% (104/104), 3.11 MiB | 9.94 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%xmode Plain\n",
        "%pdb off"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkw56Dl_9i1P",
        "outputId": "018e8341-6e52-4c2f-d551-1b5724f9201c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exception reporting mode: Plain\n",
            "Automatic pdb calling has been turned OFF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Generative-Networks/wasserstein-2/exp_2d/main.py --solver=w2 --gen=1 --data=4gaussians"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avQ7pUiQligv",
        "outputId": "17942600-094c-43cc-8977-1fa28178bbd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------ Options -------------\n",
            "activation: relu\n",
            "batch_size: 512\n",
            "beta1: 0.9\n",
            "beta2: 0.999\n",
            "clamp: False\n",
            "d_iters: 5\n",
            "d_lr: 0.0005\n",
            "d_n_layers: 3\n",
            "data: 4gaussians\n",
            "dual_iters: 20000\n",
            "eq_phi: 1\n",
            "eq_psi: 1\n",
            "exp_dir: .\n",
            "exp_name: test_run\n",
            "g_lr: 0.0001\n",
            "g_n_layers: 3\n",
            "g_norm: batch\n",
            "gen: 1\n",
            "ineq: 1\n",
            "ineq_interp: 1\n",
            "l: 2\n",
            "lambda_eq: 200\n",
            "lambda_gp: 10\n",
            "lambda_ineq: 200\n",
            "map_iters: 20000\n",
            "n_hidden: 128\n",
            "no_benchmark: False\n",
            "p: 2\n",
            "reg_type: l2\n",
            "solver: w2\n",
            "train_iters: 5000\n",
            "use_tbx: 1\n",
            "-------------- End ----------------\n",
            "2023-03-16 19:48:09.782594: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-16 19:48:10.877929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-16 19:48:10.878050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-16 19:48:10.878067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "---------- Networks initialized -------------\n",
            "[Network phi] Total number of parameters : 33537\n",
            "-----------------------------------------------\n",
            "---------- Networks initialized -------------\n",
            "[Network eps] Total number of parameters : 33537\n",
            "-----------------------------------------------\n",
            "---------- Networks initialized -------------\n",
            "[Network gen] Total number of parameters : 34434\n",
            "-----------------------------------------------\n",
            "computing discrete-OT benchmark...\n",
            "Done in 0.0776 seconds.\n",
            "Starting training...\n",
            "Step [10/5000], loss/disc: -0.2929 loss/gen: 0.7269 disp_time: 0.1082 l2_dist/discrete_T_x--G_x: 0.9958 \n",
            "Step [20/5000], loss/disc: -0.4291 loss/gen: 1.1424 disp_time: 0.0798 l2_dist/discrete_T_x--G_x: 0.9950 \n",
            "Step [30/5000], loss/disc: -0.4671 loss/gen: 1.3202 disp_time: 0.0862 l2_dist/discrete_T_x--G_x: 0.9932 \n",
            "Step [40/5000], loss/disc: -0.4762 loss/gen: 1.3760 disp_time: 0.0991 l2_dist/discrete_T_x--G_x: 0.9902 \n",
            "Step [50/5000], loss/disc: -0.4906 loss/gen: 1.4356 disp_time: 0.0777 l2_dist/discrete_T_x--G_x: 0.9865 \n",
            "Step [60/5000], loss/disc: -0.4674 loss/gen: 1.4683 disp_time: 0.0905 l2_dist/discrete_T_x--G_x: 0.9822 \n",
            "/content/Generative-Networks/wasserstein-2/exp_2d/utils.py:37: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig, ax = plt.subplots()\n",
            "Step [70/5000], loss/disc: -0.4884 loss/gen: 1.4932 disp_time: 0.0887 l2_dist/discrete_T_x--G_x: 0.9774 \n",
            "Step [80/5000], loss/disc: -0.4770 loss/gen: 1.4881 disp_time: 0.0789 l2_dist/discrete_T_x--G_x: 0.9720 \n",
            "Step [90/5000], loss/disc: -0.4726 loss/gen: 1.4954 disp_time: 0.0905 l2_dist/discrete_T_x--G_x: 0.9660 \n",
            "Step [100/5000], loss/disc: -0.4534 loss/gen: 1.5057 disp_time: 0.0841 l2_dist/discrete_T_x--G_x: 0.9593 \n",
            "Step [110/5000], loss/disc: -0.4520 loss/gen: 1.4888 disp_time: 0.0812 l2_dist/discrete_T_x--G_x: 0.9521 \n",
            "Step [120/5000], loss/disc: -0.4644 loss/gen: 1.4984 disp_time: 0.1067 l2_dist/discrete_T_x--G_x: 0.9443 \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/main.py\", line 109, in <module>\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/main.py\", line 89, in main\n",
            "    model.train_iter(config)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/base_model.py\", line 57, in train_iter\n",
            "    self.train_diter(config)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/base_model.py\", line 68, in train_diter\n",
            "    d_loss = self.calc_dloss(x, y, tx, ty, ux, vy, config)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/w2_model.py\", line 34, in calc_dloss\n",
            "    d_loss += losses.calc_interp_ineq(x, y, self.phi, self.psi, self.cost, config.lambda_ineq, losses.ineq_loss)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/losses.py\", line 52, in calc_interp_ineq\n",
            "    interp_ux, interp_vy = phi(interp_x), psi(interp_y)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/w2_model.py\", line 27, in psi\n",
            "    return -self.phi(y) + self.eps(y)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/Generative-Networks/wasserstein-2/exp_2d/networks.py\", line 40, in forward\n",
            "    output = self.model(input)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\", line 204, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 1194, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\", line 114, in forward\n",
            "    return F.linear(input, self.weight, self.bias)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/wasserstein-2.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SomvE4RFqpjd",
        "outputId": "a46a4439-bafa-426c-d582-fb635319708d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_84faf27d-9c5e-45af-8a9b-4c0d9068c665\", \"wasserstein-2.zip\", 6666508)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Insert this line wherever you wish to debug python code.\n",
        "import pdb\n",
        "pdb.set_trace()"
      ],
      "metadata": {
        "id": "QoOlZM_Xqxlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}